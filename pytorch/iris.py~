from sklearn.datasets import load_iris
from sklearn.model_modelselection import train_test_split

iris = load_iris()
X = iris['data']
y = iris['target']

# here, I am taking a deviation from the book based on my own experience
# with creating DeepNeuralNet in ../nn
# let's normalize the feature set off the bat, instead of normalizing
# the training set before training and the test set before testing

X = (X - np.mean(X)) / np.std(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1./3, random_state=1)

